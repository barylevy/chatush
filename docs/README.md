# Chatush - AI Chat Application with Pluggable Model SDK

A powerful iOS chat application that enables users to interact with multiple Large Language Model (LLM) providers through a modular SDK architecture.

## ğŸ“± Features

- **Multiple LLM Provider Support**: Switch between OpenAI and Mock (local) providers
- **Real-time Streaming**: Support for streaming responses where available
- **Conversation Management**: Full chat history with pagination support
- **Mid-Conversation Switching**: Change LLM providers without creating a new conversation
- **Secure Credential Storage**: Choose between Keychain or UserDefaults for storing API credentials
- **JSON File Storage**: Lightweight, readable conversation persistence using Codable
- **Message Management**: Delete individual messages or clear entire conversations
- **Customizable Parameters**: Adjust temperature, max tokens, and other model parameters
- **MVVM Architecture**: Clean separation of concerns with dependency injection via Factory
- **Network Logging**: Comprehensive request/response logging with header sanitization

## ğŸ—ï¸ Architecture

### Project Structure

```
Chatush/
â”œâ”€â”€ ChatushApp/                 # Main iOS AppCodable)
â”‚   â”‚   â”œâ”€â”€ Conversation.swift
â”‚   â”‚   â”œâ”€â”€ Message.swift
â”‚   â”‚   â””â”€â”€ LLMProviderConfig.swift
â”‚   â”œâ”€â”€ ViewModels/            # MVVM ViewModels
â”‚   â”‚   â”œâ”€â”€ HistoryViewModel.swift
â”‚   â”‚   â”œâ”€â”€ ChatViewModel.swift
â”‚   â”‚   â””â”€â”€ SettingsViewModel.swift
â”‚   â”œâ”€â”€ Views/                 # SwiftUI Views
â”‚   â”‚   â”œâ”€â”€ MainTabView.swift
â”‚   â”‚   â”œâ”€â”€ ConversationsView.swift
â”‚   â”‚   â”œâ”€â”€ ChatView.swift
â”‚   â”‚   â”œâ”€â”€ ChatSettingsView.swift
â”‚   â”‚   â”œâ”€â”€ SettingsView.swift
â”‚   â”‚   â””â”€â”€ AboutView.swift
â”‚   â”œâ”€â”€ Repositories/          # Data repository layer
â”‚   â”‚   â”œâ”€â”€ ConversationsRepositoryProtocol.swift
â”‚   â”‚   â””â”€â”€ ConversationsRepository.swift
â”‚   â”œâ”€â”€ Storage/               # Storage implementations
â”‚   â”‚   â”œâ”€â”€ CredentialsStorageProtocol.swift
â”‚   â”‚   â”œâ”€â”€ KeychainCredentialsStorage.swift
â”‚   â”‚   â”œâ”€â”€ UserDefaultsCredentialsStorage.swift
â”‚   â”‚   â””â”€â”€ FileStorageManager.swift
â”‚   â”œâ”€â”€ Extensions/            # SwiftUI and other extensions
â”‚   â”‚   â”œâ”€â”€ View+Extensions.swift
â”‚   â”‚   â””â”€â”€ Publishers+Keyboard.swift
â”‚   â””â”€â”€ DependencyInjection/   # Factory DI container
â”‚       â””â”€â”€ AppContainer.swift
â”‚
â””â”€â”€ ChatushSDK/                # Modular SDK Package
    â””â”€â”€ Sources/
        â””â”€â”€ ChatushSDK/
            â”œâ”€â”€ Models/
            â”‚   â”œâ”€â”€ ModelConfiguration.swift
            â”‚   â”œâ”€â”€ ModelResponse.swift
            â”‚   â””â”€â”€ ChatMessage.swift
            â”œâ”€â”€ Protocols/
            â”‚   â””â”€â”€ ModelProviderProtocol.swift
            â”œâ”€â”€ Providers/
            â”‚   â”œâ”€â”€ OpenAIModelProvider.swift
            â”‚   â””â”€â”€ MockModelProvider.swift
            â”œâ”€â”€ Router/
            â”‚   â””â”€â”€ ModelRouter.swift
            â”œâ”€â”€ Network/
            â”‚   â”œâ”€â”€ NetworkClient.swift
            â”‚   â””â”€â”€ DefaultNetworkLogg
            â”‚   â””â”€â”€ ModelRouter.swift
            â”œâ”€â”€ Errors/
            â”‚   â””â”€â”€ ModelProviderError.swift
            â””â”€â”€ ChatushSDK.swift
```

### Design Patterns

- **MVVM (Model-View-ViewModel)**: Clean separation between UI and business logic
- **Repository Pattern**: Abstracts data access layer
- **Dependency Injection**: Uses Factory framework for testable, modular code
- **Protocol-Oriented**: Protocols for all major components enabling easy testing
- **Factory Pattern**: ModelRouter determines which provider to use

## ğŸ”§ Setup Instructions

### Prerequisites

- Xcode 15.0+ (for iOS 18.0+ support)
- iOS 18.0+ device or simulator
- OpenAI API key (for OpenAI provider)

### Installation

1. **Clone the repository**
   ```bash
   cd /Users/bari.levi/Dev_env/Chatush
   ```

2. **Open the project in Xcode**
   ```bash
   open ChatushApp.xcodeproj
   ```

3. **Build the project**
   - The ChatushSDK will be automatically built as a local Swift Package
   - Factory dependency will be downloaded automatically

4. **Run the application**
   - Select a simulator or device
   - Press `Cmd+R` to build and run

## ğŸš€ Usage

### First Time Setup

1. Launch the app
2. Navigate to the **Settings** tab (gear icon)
3. Choose your storage type (Keychain recommended for security)
4. Select a provider:
   - **OpenAI**: Requires API key
   - **Mock**: Works without configuration for testing

### For OpenAI Provider

1. In Settings, select "OpenAI" as the provider
2. Enter your OpenAI API key
3. Set the model (e.g., `gpt-4o-mini`, `gpt-3.5-turbo`)
4. (Optional) Customize temperature and max tokens
5. Tap "Test Connection" to verify
6. Tap "Save Configuration"

### For Mock Provider

1. In Settings, select "Mock" as the provider
2. No API key required
3. Tap "Save Configuration"

### Starting a Chat

1. Navigate to the **Chat** tab (message icon)
2. Type your message in the input field
3. Tap the send button
4. Watch the response appear (with streaming if supported)

### Managing Conversations

- **View History**: Check the **History** tab for all past conversations
- **Continue Chat**: Tap any conversation to continue
- **Delete Conversation**: Swipe left on a conversation
- **Clear Messages**: Use the menu (â€¢â€¢â€¢) in chat view
- **Select & Delete**: Use selection mode to delete multiple messages

### Switching Providers Mid-Conversation

1. Go to **Settings**
2. Change the provider or model
3. Save the configuration
4. Return to your chat - new messages will use the new provider

## ğŸ”Œ SDK Integration

### Real API: OpenAI

The SDK integrates with OpenAI's Chat Completions API:

**Endpoint**: `https://api.openai.com/v1/chat/completions`

**Supported Features**:
- Standard completion
- Streaming responses
- Multiple models (GPT-4, GPT-3.5-turbo, etc.)
- Temperature and token control

### Mock Provider

The mock provider simulates AI responses:
- Echoes the user's message
- Adds a random predefined response
- Simulates network latency
- Supports streaming simulation

## ğŸ“Š SDK Routing Logic

The `ModelRouter` determines which provider to use:

```swift
// Configuration determines the provider
let config = ModelConfiguration(
    provider: "openai",  // or "mock"
    model: "gpt-4o-mini",
    apiKey: "your-api-key",
    endpoint: nil,  // optional, defaults to OpenAI
    temperature: 0.7,
    maxTokens: 2000
)

// Router selects the appropriate provider
let response = try await sdk.sendMessage(messages: messages, config: config)
```

### Provider Selection Flow

1. App reads configuration from storage (Keychain/UserDefaults)
2. Configuration passed to SDK via `ModelConfiguration`
3. `ModelRouter` looks up provider by name
4. Router delegates to appropriate `ModelProvider` implementation
5. Provider formats request for its specific API
6. Response is normalized to common `ModelResponse` format
7. App receives consistent response regardless of provider

## ğŸ§ª Testing

The architecture is designed for testability:

- **Protocols**: All major components are protocol-based
- **Dependency Injection**: Factory enables easy mocking
- **Repository Pattern**: Data layer can be mocked
- **Provider Pattern**: Easy to create test providers

### Future Test Implementation

```swift
// Example: Mock repository for testing
class MockConversationsRepository: ConversationsRepositoryProtocol {
    var mockConversations: [Conversation] = []
    // Implement protocol methods...
}

// Register in tests
Container.shared.conversationsRepository.register {
    MockConversationsRepository()
}
```

  - Includes: NetworkClient with request/response logging

## ğŸ“ Data Storage

### Conversation Storage

All conversations are stored in JSON format in the app's Documents directory:

**File**: `conversations.json`

**Format**:
```json
[
  {
    "id": "UUID",
    "title": "Conversation Title",
    "createdAt": "2025-12-28T10:00:00Z",
    "updatedAt": "2025-12-28T10:05:00Z",
    "providerName": "openai",
    "modelName": "gpt-4o-mini",
    "messages": [
      {
        "id": "UUID",
        "content": "Hello",
        "timestamp": "2025-12-28T10:00:00Z",
        "isFromUser": true,
        "latencyMs": null
      },
      {
        "id": "UUID",
        "content": "Hi! How can I help?",
        "timestamp": "2025-12-28T10:00:02Z",
        "isFromUser": false,
        "latencyMs": 1234
      }
    ]
  }
]
```

### Credentials Storage

API keys and configurations stored using selected method:
- **Keychain**: Secure, encrypted storage (recommended)
- **UserDefaults**: Simple key-value storage (development/testing)

### Observable Models

Both `Conversation` and `Message` use `@Observable` macro:
- Automatic UI updates when data changes
- No manual state management needed
- Works seamlessly with SwiftUI bindings
## ğŸ“¦ Dependencies

- **Factory** (2.3.0+): Dependency injection framework
  - Source: https://github.com/hmlongco/Factory
  - Used for: Managing all app dependencies
  
- **ChatushSDK** (Local Package): Custom LLM abstraction SDK
  - Provides: Unified interface for multiple LLM providers

## ğŸ” Security

- **Keychain Storage**: Secure storage for API keys (recommended)
- **UserDefaults Option**: Alternative for non-sensitive scenarios
- **No Hardcoded Keys**: All credentials stored securely
- **HTTPS Only**: All network requests use secure connections

## ğŸ¯ Design Decisions
JSON File Storage?

- Lightweight and simple for small to medium datasets
- Human-readable format for debugging
- Easy migration and backup
- No database overhead
- Perfect fit for chat history with Observable models
- Instant loading with async/await

### Why Actor for SDK and Storage?

- Thread-safe by default
- Perfect for async/await
- Prevents data races
- No manual locking required
- Ensures consistency in file operationsreData
- Seamless SwiftUI integration

### Why Actor for SDK?

- Thread-safe by default
- Perfect for async/await
- Prevents data races
- No manual locking required

### Two Storage Implementations?

- **Keychain**: Production-ready, secure for API keys
- **UserDefaults**: Simpler, useful for testing/development
- **Factory**: Enables runtime switching via settings

## ğŸŒŸ Screenshots

### Main Screens

1. **History Tab**: List of all conversations with paging
2. **Chat Tab**: WhatsApp-style chat interface with streaming
3. **Settings Tab**: Configure provider, credentials, and parameters
4. **About Tab**: App information and feature overview

## ğŸ”® Future Enhancements (Optional)

- [ ] Additional providers (Anthropic Claude, Google Gemini, Mistral)
- [ ] Token usage tracking and display
- [ ] Export conversation history
- [ ] Search within conversations
- [ ] Voice input support
- [ ] Dark mode optimization
- [ ] Widget support
- [ ] iCloud sync
- [ ] Unit and UI tests

## ğŸ“ Configuration Example

### OpenAI Configuration

```json
{
  "provider": "openai",
  "model": "gpt-4o-mini",
  "apiKey": "sk-...",
  "endpoint": "https://api.openai.com/v1/chat/completions",
  "temperature": 0.7,
  "maxTokens": 2000
}
```

### Mock Configuration

```json
{
  "provider": "mock",
  "model": "mock-v1",
  "apiKey": null,
  "endpoint": null,
  "temperature": 0.7,
  "maxTokens": 2000
}
```

## ğŸ› Troubleshooting

### "Failed to load configuration"
- Check storage type in Settings
- Try switching between Keychain and UserDefaults

### "API Error (401)"
- Verify your OpenAI API key is correct
- Check if key has proper permissions

### "Network error"
- Check internet connection
- Verify endpoint URL (or leave blank for default)

### Messages not streaming
- Check if provider supports streaming (OpenAI does, Mock does)
- Verify network connection stability

## ğŸ“„ License

This project is created as a demonstration of iOS development skills.

## ğŸ‘¤ Author

**Bari Levi**
- Development Environment: Xcode 15, iOS 18
- Architecture: MVVM with Factory DI
- Date: December 2025

---

Built with â¤ï¸ using Swift and SwiftUI
